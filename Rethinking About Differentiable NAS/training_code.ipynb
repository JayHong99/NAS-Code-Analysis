{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## markdown 파일에 따르면, 아래의 코드를 실행해야 함 (상세 Argument는 제외)\n",
    "```bash\n",
    "cd nasbench201 && bash darts-201.sh\n",
    "```\n",
    "⇒ [darts-201.sh](http://darts-201.sh) 파일을 보니, train_serach.py를 실행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "main : nasbench201.train.py\n",
    "\n",
    "sub1 : nasbench201.cell_operations.SearchSpaceNames => 하단 설명\n",
    "sub2 : nasbench201.search_model_darts.TinyNetworkDarts => 다른 파일에서 설명\n",
    "sub3 : nasbench201.search_model_darts_proj.TinyNetworkDartsProj => 다른 파일에서 설명\n",
    "sub4 : nasbench201.architect_ig.Architect => 하단 설명\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments\n",
    "- `--data`: 데이터셋의 위치\n",
    "- `--dataset` : 데이터셋의 이름, cifar10, cifar100, ImageNet16-120 중 하나\n",
    "- `--method`: NAS 방법, dirichlet\n",
    "- `--search_space` : search space의 이름, nas-bench-201\n",
    "- `--batch_size` : batch size, default : 64\n",
    "- `--learning_rate` : learning rate, default : 0.025\n",
    "- `--learning_rate_min` : minimum learning rate, default : 0.001\n",
    "- `--momentum` : momentum, default : 0.9\n",
    "- `--weight_decay` : weight decay, default : 3e-4\n",
    "- `--report_freq` : report frequency, default : 50\n",
    "- `--gpu` : gpu id, default : 'auto'\n",
    "- `--epochs` : epochs, default : 100\n",
    "- `--init_channels` : initial channels, default : 16\n",
    "- `--layers` : layers, default : 8\n",
    "- `--model_path` : model path, default : 'saved_models'\n",
    "- `--cutout` : cutout, default : False\n",
    "- `--cutout_length` : cutout length, default : 16\n",
    "- `--cutout_prob` : cutout probability, default : 1.0\n",
    "- `--save` : save, default : 'exp'\n",
    "- `--seed` : seed, default : 2\n",
    "- `--grad_clip` : grad clip, default : 5\n",
    "- `--train_portion` : train portion, default : 0.5\n",
    "- `--arch_learning_rate` : arch learning rate, default : 3e-4\n",
    "- `--arch_weight_decay` : arch weight decay, default : 1e-3\n",
    "- `--fast` : 사전 학습된 모델 구조를 가져옴, default : False\n",
    "- `--resume_epoch` : resume epoch, default : 0\n",
    "- `--resume_expid` : resume expid, default : ''\n",
    "- `--dev` : dev, default : None\n",
    "- `--ckpt_interval` : ckpt interval, default : 20\n",
    "- `--expid_tag` : expid tag, default : 'none'\n",
    "- `--log_tag` : log tag, default : ''\n",
    "- `--edge_decision` : edge decision, default : 'random'\n",
    "- `--proj_crit` : proj crit, default : 'acc'\n",
    "- `--proj_intv` : proj intv, default : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'cifar100': n_classes = 100\n",
    "elif args.dataset == 'imagenet16-120': n_classes = 120\n",
    "else: n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1 : cifar100 : 100개의 클래스<br>\n",
    "line 2 : imagenet16-120 : 120개의 클래스<br>\n",
    "line 3 : cifar10 : 10개의 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(3)\n",
    "if not torch.cuda.is_available():\n",
    "    logging.info('no gpu device available')\n",
    "    sys.exit(1)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "gpu = ig_utils.pick_gpu_lowest_memory() if args.gpu == 'auto' else int(args.gpu)\n",
    "torch.cuda.set_device(gpu)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1 : 3개의 thread 사용<br>\n",
    "line 2~4 : GPU가 불가능하면 PASS<br>\n",
    "line 6 : seed 고정<br>\n",
    "line 7 : GPU 사용(auto면 GPU가 제일 적게 쓰이고 있는 GPU를 선택)<br>\n",
    "line 8 : GPU 세팅<br>\n",
    "line 9~12 : Reproducibility를 위한 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.fast:\n",
    "    api = API('../data/NAS-Bench-201-v1_0-e61699.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1~2 : 사전학습된 모델 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "search_space = SearchSpaceNames[args.search_space]\n",
    "if args.method in ['darts', 'blank']:\n",
    "    model = TinyNetworkDarts(C=args.init_channels, N=5, max_nodes=4, num_classes=n_classes, criterion=criterion, search_space=search_space, args=args)\n",
    "elif args.method in ['darts-proj', 'blank-proj']:\n",
    "    model = TinyNetworkDartsProj(C=args.init_channels, N=5, max_nodes=4, num_classes=n_classes, criterion=criterion, search_space=search_space, args=args)\n",
    "model = model.cuda()\n",
    "\n",
    "architect = Architect(model, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1 : creiterion : nn.CrossEntropy()<br>\n",
    "line 2 : search_space : 하단 참조\n",
    "```\n",
    "CONNECT_NAS_BENCHMARK = ['none', 'skip_connect', 'nor_conv_3x3']\n",
    "NAS_BENCH_201         = ['none', 'skip_connect', 'nor_conv_1x1', 'nor_conv_3x3', 'avg_pool_3x3']\n",
    "DARTS_SPACE           = ['none', 'skip_connect', 'dua_sepc_3x3', 'dua_sepc_5x5', 'dil_sepc_3x3', 'dil_sepc_5x5', 'avg_pool_3x3', 'max_pool_3x3']\n",
    "NAS_BENCH_201_SKIP    = ['none', 'skip_connect', 'nor_conv_1x1_skip', 'nor_conv_3x3_skip', 'avg_pool_3x3']\n",
    "NAS_BENCH_201_SIMPLE  = ['skip_connect', 'nor_conv_1x1', 'nor_conv_3x3', 'avg_pool_3x3']\n",
    "NAS_BENCH_201_S2      = ['skip_connect', 'nor_conv_3x3']\n",
    "NAS_BENCH_201_S4      = ['noise', 'nor_conv_3x3']\n",
    "NAS_BENCH_201_S10     = ['none', 'nor_conv_3x3']\n",
    "```\n",
    "line 3~4 : TinyNetworkDarts for DARTS, Blank ( 다른 파일 추가 설명 참조 )<br>\n",
    "line 5~6 : TinyNetworkDartsProj for DARTS-proj, Blank-proj ( 다른 파일 추가 설명 참조 )<br>\n",
    "line 7 : model to gpu<br>\n",
    "line 9 : Architecture에 포함 ( 다음 Cell 추가 설명 참조 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architect(object):\n",
    "    def __init__(self, model, args):\n",
    "        self.network_momentum = args.momentum\n",
    "        self.network_weight_decay = args.weight_decay\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.Adam(self.model.arch_parameters(),\n",
    "                                        lr=args.arch_learning_rate, betas=(0.5, 0.999),\n",
    "                                        weight_decay=args.arch_weight_decay)\n",
    "        self._init_arch_parameters = []\n",
    "        for alpha in self.model.arch_parameters():\n",
    "            alpha_init = torch.zeros_like(alpha)\n",
    "            alpha_init.data.copy_(alpha)\n",
    "            self._init_arch_parameters.append(alpha_init)\n",
    "        if args.method in ['darts', 'darts-proj', 'sdarts', 'sdarts-proj']:\n",
    "            self.method = 'fo' # first order update\n",
    "        elif 'so' in args.method:\n",
    "            print('ERROR: PLEASE USE architect.py for second order darts')\n",
    "        elif args.method in ['blank', 'blank-proj']:\n",
    "            self.method = 'blank'\n",
    "        else:\n",
    "            print('ERROR: WRONG ARCH UPDATE METHOD', args.method); exit(0)\n",
    "    def reset_arch_parameters(self):\n",
    "        for alpha, alpha_init in zip(self.model.arch_parameters(), self._init_arch_parameters):\n",
    "            alpha.data.copy_(alpha_init.data)\n",
    "    def step(self, input_train, target_train, input_valid, target_valid, *args, **kwargs):\n",
    "        if self.method == 'fo':\n",
    "            shared = self._step_fo(input_train, target_train, input_valid, target_valid)\n",
    "        elif self.method == 'so':\n",
    "            raise NotImplementedError\n",
    "        elif self.method == 'blank': ## do not update alpha\n",
    "            shared = None\n",
    "        return shared\n",
    "    #### first order\n",
    "    def _step_fo(self, input_train, target_train, input_valid, target_valid):\n",
    "        loss = self.model._loss(input_valid, target_valid)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return None\n",
    "    #### darts 2nd order\n",
    "    def _step_darts_so(self, input_train, target_train, input_valid, target_valid, eta, model_optimizer):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1 : Architecture<br>\n",
    "line 2~21 : Initialization<br>\n",
    "- line 3 : network_momenum : argument에 있는 momentum\n",
    "- line 4 : network_weight_decay : argument에 있는 weight decay\n",
    "- line 5 : model : model\n",
    "- line 6~8 : Optimizer 세팅\n",
    "    - line 6 : self.model.arch_paramters : 모델 파라미터\n",
    "    - line 7 : lr : argument에 있는 arch learning rate, betas : (0.5, 0.999)\n",
    "    - line 8 : weight_decay : argument에 있는 arch weight decay\n",
    "- line 9~13 : 모델 weight를 0으로 만들었을 때의 weight를 self._init_arch_parameters에 저장\n",
    "- line 14~21 : self.method 등록\n",
    "    - line 14~15 : DARTS, DARTS-proj, SDARTS, SDARTS-proj이면 self.proj = 'fo' : first order\n",
    "    - line 16~17 : 'so' in arg.method : second order, error\n",
    "    - line 18~19 : BLANK, BLANK-PROJ =  'blank'\n",
    "    - line 20~21 : error<br>\n",
    "\n",
    "line 22~24 : reset_arch_parameters : 모델 파라미터를 0으로 초기화<br>\n",
    "line 25~32 : step : 모델 업데이트\n",
    "- line 25 : 함수 정의\n",
    "- line 26~27 : first order들 업데이트\n",
    "    - shared = self._step_fo\n",
    "- line 28~29 : second order들 업데이트\n",
    "    - not implemented\n",
    "- line 30~31 : blank들 업데이트\n",
    "    - shared = None\n",
    "- line 32 : `return shared`<br>\n",
    "\n",
    "line 34~38 : first order 업데이트\n",
    "- line 35 : loss 계산\n",
    "- line 36 : loss 역전파\n",
    "- line 37 : optimizer step\n",
    "- return None\n",
    "\n",
    "line 40~41 : second order : Not Implemented Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'cifar10':\n",
    "    train_transform, valid_transform = ig_utils._data_transforms_cifar10(args)\n",
    "    train_data = dset.CIFAR10(root=args.data, train=True, download=True, transform=train_transform)\n",
    "    valid_data = dset.CIFAR10(root=args.data, train=False, download=True, transform=valid_transform)\n",
    "elif args.dataset == 'cifar100':\n",
    "    train_transform, valid_transform = ig_utils._data_transforms_cifar100(args)\n",
    "    train_data = dset.CIFAR100(root=args.data, train=True, download=True, transform=train_transform)\n",
    "    valid_data = dset.CIFAR100(root=args.data, train=False, download=True, transform=valid_transform)\n",
    "elif args.dataset == 'imagenet16-120':\n",
    "    import torchvision.transforms as transforms\n",
    "    from nasbench201.DownsampledImageNet import ImageNet16\n",
    "    mean = [x / 255 for x in [122.68, 116.66, 104.01]]\n",
    "    std = [x / 255 for x in [63.22,  61.26, 65.09]]\n",
    "    lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(16, padding=2), transforms.ToTensor(), transforms.Normalize(mean, std)]\n",
    "    train_transform = transforms.Compose(lists)\n",
    "    train_data = ImageNet16(root=os.path.join(args.data,'imagenet16'), train=True, transform=train_transform, use_num_of_class_only=120)\n",
    "    valid_data = ImageNet16(root=os.path.join(args.data,'imagenet16'), train=False, transform=train_transform, use_num_of_class_only=120)\n",
    "    assert len(train_data) == 151700\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(args.train_portion * num_train))\n",
    "\n",
    "train_queue = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=args.batch_size,\n",
    "    sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n",
    "    pin_memory=True)\n",
    "valid_queue = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=args.batch_size,\n",
    "    sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:num_train]),\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1~4 : CIFAR10 Load Train, Test Datasets<br>\n",
    "line 5~8 : CIFAR100 Load Train, Test Datasets<br>\n",
    "line 9~18 : ImageNet16-120 Load Train, Test Datasets<br>\n",
    "line 20 : 데이터 크기<br>\n",
    "line 21 : indices<br>\n",
    "line 22 : split size : TRAIN : VALID Split<br>\n",
    "line 24~27 : Train DataLoader<br>\n",
    "line 28~31 : Valid DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    model.optimizer, float(args.epochs), eta_min=args.learning_rate_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1~2 : Scheduler 세팅\n",
    "- CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Point 세팅이 되어있으면, 해당 세팅을 불러온다.\n",
    "start_epoch = 0\n",
    "if args.resume_epoch != 0:\n",
    "    checkpoint = torch.load(filename, map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch'] # epoch\n",
    "    model_state_dict = checkpoint['state_dict']\n",
    "    if '_arch_parameters' in model_state_dict: del model_state_dict['_arch_parameters']\n",
    "    model.load_state_dict(model_state_dict) # model\n",
    "    saved_arch_parameters = checkpoint['alpha'] # arch\n",
    "    model.set_arch_parameters(saved_arch_parameters)\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    model.optimizer.load_state_dict(checkpoint['optimizer']) # optimizer\n",
    "    architect.optimizer.load_state_dict(checkpoint['arch_optimizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 2~13 : 세팅 불러오기\n",
    "- line 2 : start epoch\n",
    "- line 3 : resume_epoch가 남아있을 경우 실행\n",
    "- line 3~13 : 학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, args.epochs):\n",
    "    lr = scheduler.get_lr()[0]\n",
    "    if args.cutout:\n",
    "        train_transform.transforms[-1].cutout_prob = args.cutout_prob * epoch / (args.epochs - \n",
    "    genotype = model.genotype()\n",
    "    train_acc, train_obj = train(train_queue, valid_queue, model, architect, model.optimizer, lr, epoch)\n",
    "    valid_acc, valid_obj = infer(valid_queue, model, criterion, log=False)\n",
    "    scheduler.step()\n",
    "    save_state = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'alpha': model.arch_parameters(),\n",
    "        'optimizer': model.optimizer.state_dict(),\n",
    "        'arch_optimizer': architect.optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict()\n",
    "    }\n",
    "    if save_state['epoch'] % args.ckpt_interval == 0:\n",
    "        ig_utils.save_checkpoint(save_state, False, args.save, per_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1~18 : Train Model\n",
    "- line 1 : for loop\n",
    "- line 2 : get learning rate\n",
    "- line 3~4 : change cutout prob\n",
    "    - line 4 : increase cutout ratio while epoch increases (ex : 0.025 if epoch == 1 else 0.5 if epoch == 200, epochs = 200)\n",
    "- line 5 : genotype 설정, TinyNetworkDarts 참조\n",
    "- line 6 : train : 하단 참조\n",
    "- line 7 : infer : 하단 참조\n",
    "- line 8 : scheduler 업데이트\n",
    "- line 9~16 : save 할 정보들 업데이트\n",
    "- 17~18 : epoch가 저장할 때마다 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_queue, valid_queue, model, architect, optimizer, lr, epoch):\n",
    "    objs = ig_utils.AvgrageMeter()\n",
    "    top1 = ig_utils.AvgrageMeter()\n",
    "    top5 = ig_utils.AvgrageMeter()\n",
    "    for step in range(len(train_queue)):\n",
    "        model.train()\n",
    "        input, target = next(iter(train_queue))\n",
    "        input = input.cuda(); target = target.cuda(non_blocking=True)\n",
    "        input_search, target_search = next(iter(valid_queue))\n",
    "        input_search = input_search.cuda(); target_search = target_search.cuda(non_blocking=True)\n",
    "        optimizer.zero_grad(); architect.optimizer.zero_grad()\n",
    "        shared = architect.step(input, target, input_search, target_search,\n",
    "                                eta=lr, network_optimizer=optimizer)\n",
    "        optimizer.zero_grad(); architect.optimizer.zero_grad()\n",
    "        logits, loss = model.step(input, target, args, shared=shared)\n",
    "        prec1, prec5 = ig_utils.accuracy(logits, target, topk=(1, 5))\n",
    "        n = input.size(0)\n",
    "        objs.update(loss.data, n)\n",
    "        top1.update(prec1.data, n)\n",
    "        top5.update(prec5.data, n)\n",
    "        if args.fast:\n",
    "            break\n",
    "    return top1.avg, objs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 1~23 : training code\n",
    "- line 1 : function define\n",
    "- line 2~4 : AvgrageMeter(), 하단 참조\n",
    "- line 5 : Data Loader\n",
    "- line 6 : make model training mode\n",
    "- line 7 : load training input and target\n",
    "- line 8 : input, target to gpu\n",
    "- line 9 : load validation input and target\n",
    "- line 11~13 : update model architecture alpha\n",
    "    - line 11 : zero grad for model and architecture\n",
    "    - line 12~13 : update architecture\n",
    "- line 14~15 : update model weight\n",
    "    - line 14 : zero grad for model and architecture\n",
    "    - line 15 : update model weight\n",
    "- line 16 : get accuracy\n",
    "- line 17 : get batch size\n",
    "- line 18~20 : update avgmeter\n",
    "    - line 18 : update loss\n",
    "    - line 19 : update top1 acc\n",
    "    - line 20 : update top5 acc\n",
    "- line 21~22 : break\n",
    "    - line 21 : if args.fast : 사전 학습된 모델의 구조이면,\n",
    "    - line 22 : break -> 학습된 모델임\n",
    "- line 23 : top1.avg, objs.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgrageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 3 : init <br>\n",
    "line 4 : reset, set avg, sum, cnt<br>\n",
    "line 11~14 : update, arguments : value, n=1<br>\n",
    "- line 12 : sum all values<br>\n",
    "- line 13 : sum all counts<br>\n",
    "- line 14 : average of all values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(valid_queue, model, criterion,\n",
    "          log=True, eval=True, weights=None, double=False, bn_est=False):\n",
    "    objs = ig_utils.AvgrageMeter()\n",
    "    top1 = ig_utils.AvgrageMeter()\n",
    "    top5 = ig_utils.AvgrageMeter()\n",
    "    model.eval() if eval else model.train() # disable running stats for projection\n",
    "    if bn_est:\n",
    "        _data_loader = deepcopy(valid_queue)\n",
    "        for step, (input, target) in enumerate(_data_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input)\n",
    "        model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (input, target) in enumerate(valid_queue):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            if double:\n",
    "                input = input.double(); target = target.double()\n",
    "            logits = model(input) if weights is None else model(input, weights=weights)\n",
    "            loss = criterion(logits, target)\n",
    "            prec1, prec5 = ig_utils.accuracy(logits, target, topk=(1, 5))\n",
    "            n = input.size(0)\n",
    "            objs.update(loss.data, n)\n",
    "            top1.update(prec1.data, n)\n",
    "            top5.update(prec5.data, n)\n",
    "            if args.fast:\n",
    "                break\n",
    "    return top1.avg, objs.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상세 설명은 생략\n",
    "- bn_est : validation data도 업데이트? => 사용 안함\n",
    "- double : double precision (float64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
